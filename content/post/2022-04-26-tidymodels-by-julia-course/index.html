---
title: tidymodels by julia course
author: shuqiang
date: '2022-04-26'
slug: []
categories:
  - R
tags:
  - tidymodels
subtitle: ''
description: ''
image: ''

---



<div id="pca-and-umap-with-tidymodels-and-cocktail-recipes" class="section level2">
<h2>1. PCA and UMAP with tidymodels and cocktail recipes</h2>
</div>
<div id="impute-missing-data-for-historical-voyages-of-captive-africans-usin" class="section level2">
<h2>2. Impute missing data for historical voyages of captive Africans usin</h2>
<p>To build a model to understand more about <a href="https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-06-16/readme.md">the forced transport of captive Africans from this week’s #tidytuesday dataset</a></p>
<div id="explore-the-data" class="section level3">
<h3>Explore the data</h3>
<pre class="r"><code># african_names &lt;- readr::read_csv(&#39;https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-06-16/african_names.csv&#39;)
african_names &lt;- readr::read_csv(&#39;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-06-16/african_names.csv&#39;)</code></pre>
<pre class="r"><code>skimr::skim(african_names)
view(african_names)

african_names %&gt;% count(port_disembark, sort = TRUE)
african_names %&gt;% count(port_embark, sort = TRUE)
summary(african_names$year_arrival)</code></pre>
<pre class="r"><code>african_names %&gt;%
  ggplot(aes(year_arrival)) +
  geom_histogram(bins = 20, alpha = 0.7)</code></pre>
<pre class="r"><code>african_names %&gt;% 
  filter(year_arrival &lt; 1850) %&gt;% 
  group_by(year_arrival) %&gt;% 
  summarise(age = mean(age, na.rm = TRUE)) %&gt;% 
  ggplot(aes(year_arrival, age)) +
  geom_line(alpha = 0.6, size = 1.5) +
  geom_smooth(method = &#39;lm&#39;) +
  scale_y_continuous(limits = c(0, NA))</code></pre>
<pre class="r"><code>african_names %&gt;% 
  ggplot(aes(gender, year_arrival, fill = gender)) +
  geom_boxplot(alpha = 0.4, show.legend = FALSE)
african_names %&gt;% 
  ggplot(aes(gender, age, fill = gender)) +
  geom_boxplot(alpha = 0.4, show.legend = FALSE) ## 将Boy和Girl合并</code></pre>
<pre class="r"><code>library(ggrepel)
african_names %&gt;% 
  group_by(name) %&gt;% 
  summarise(n = n(),
            age = mean(age, na.rm = TRUE),
            year_arrival = mean(year_arrival, na.rm = TRUE)) %&gt;% 
  ungroup() %&gt;%
  fitler(n &gt; 30) %&gt;% 
  ggplot(aes(year_arrival, age)) +
  geom_point(aes(size = n), alpha = 0.7) +
  geom_text_repel(aes(label = name), size = 3, family = &#39;IBMPlexSans-Bold&#39;)
  labs(size = &#39;Number of people&#39;)</code></pre>
<pre class="r"><code>library(naniar)
african_names %&gt;% 
  select(gender, height, age) %&gt;% 
  gg_miss_upset()</code></pre>
</div>
<div id="impute-missing-data" class="section level3">
<h3>Impute missing data</h3>
<pre class="r"><code>liberated_df &lt;- african_names %&gt;% 
  filter(year_arrival &lt; 1850) %&gt;% 
  mutate(gender = case_when(gender == &#39;Boy&#39; ~ &#39;Man&#39;,
                            gender == &#39;Girl&#39; ~ &#39;Woman&#39;,
                            TRUE ~ gender)) %&gt;% 
  mutate_if(is.character, factor)</code></pre>
<pre class="r"><code>library(recipes)
# recipe只是添加命令，但是没有运行
impute_rec &lt;- recipe(year_arrival ~ gender + age + height, data = liberated_df) %&gt;%
  step_meanimpute(height) %&gt;% 
  step_knnimpute(all_predictors())</code></pre>
<pre class="r"><code>## prep会执行impute_rec中的命令
imputed &lt;- prep(impute_rec) %&gt;% juice() ;imputed

summary(liberated_df$gender)
summary(imputed$gender)

summary(liberated_df$age)
summary(imputed$age)</code></pre>
</div>
<div id="fit-model" class="section level3">
<h3>Fit model</h3>
<pre class="r"><code>fit_lm = lm(year_arrival ~ gender + age, data = imputed)
tidy(fit_lm)</code></pre>
</div>
</div>
<div id="tuning-xgboost-using-tidymodels-选择最好的参数" class="section level2">
<h2>3. Tuning XGBoost using tidymodels: 选择最好的参数</h2>
<p>XGBoost(eXtreme Gradient Boosting)极致梯度提升，是一种基于GBDT的算法或者说工程实现。
基于决策树。</p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/162001079">XGBoost的原理、公式推导、Python实现和应用</a></li>
</ul>
<p>Let’s build a model for <a href="https://github.com/jhrcook/tidy-tuesday/blob/master/data/2020-05-19_beach-volleybal.md">beach volleybal matches from this week’s #tidytuesday dataset</a>.
Let’s tune an xgboost model and predict wins from game play stats like errors, blocks, attacks, etc.</p>
<div id="explore-the-data-1" class="section level3">
<h3>Explore the data</h3>
<pre class="r"><code>vb_match &lt;- read_csv(&#39;https://raw.github.com/jhrcook/tidy-tuesday/blon/master/data/2020-05-19/vb_matches.csv&#39;,
                     guess_max = 76000)
vb_match %&gt;% view()</code></pre>
<pre class="r"><code>vb_parsed &lt;- vb_match %&gt;% 
  transmute(circuit,
            gender,
            year,
            w_attacks = w_p1_tot_attacks + w_p2_tot_attacks,
            w_kills = w_p1_tot_kills + w_p2_tot_kills,
            w_erros = w_p1_tot_errors + w_p2_tot_errors,
            w_aces = w_p1_tot_aces + w_p2_tot_aces,
            w_serve_errors = w_p1_tot_serve_errors + w_p2_tot_serve_errors,
            w_blocks = w_p1_tot_blocks + w_p2_tot_blocks,
            w_digs = w_p1_tot_digs + w_p1_tot_digs,
            l_attacks = l_p1_tot_attacks + l_p2_tot_attacks,
            l_kills = l_p1_tot_kills + l_p2_tot_kills,
            l_erros = l_p1_tot_errors + l_p2_tot_errors,
            l_aces = l_p1_tot_aces + l_p2_tot_aces,
            l_serve_errors = l_p1_tot_serve_errors + l_p2_tot_serve_errors,
            l_blocks = l_p1_tot_blocks + l_p2_tot_blocks,
            l_digs = l_p1_tot_digs + l_p1_tot_digs
            ) %&gt;% 
  na.omit()

winners &lt;- vb_parsed %&gt;% 
  select(circuit, gender, year, w_attacks:w_digs) %&gt;% 
  rename_with(~ str_remove_all(., &#39;w_&#39;), w_attacks:w_digs) %&gt;% 
  mutate(win = &#39;win&#39;)

losers &lt;- vb_parsed %&gt;% 
  select(circuit, gender, year, l_attacks:l_digs) %&gt;% 
  rename_with(~ str_remove_all(., &#39;l_&#39;), l_attacks:l_digs) %&gt;% 
  mutate(win = &#39;lose&#39;)

vb_df &lt;- bind_rows(winners, losers) %&gt;% 
  muttae_if(as.character, factor)

vb_df %&gt;% count(gender)
vb_df %&gt;% count(circuit)</code></pre>
<pre class="r"><code>vb_df %&gt;% 
  pivot_longer(attacks:digs, names_to = &#39;stat&#39;, values_to = &#39;value&#39;) %&gt;% 
  ggplot(aes(gender, value, fill = win, color = win)) +
  geom_boxplot(alpha = 0.4) +
  facet_wrap( ~ stat, scales = &#39;free_y&#39;, nrow = 2) +
  labs(y = NULL, color = NULL, fill = NULL)</code></pre>
</div>
<div id="build-a-model" class="section level3">
<h3>Build a model</h3>
<pre class="r"><code>library(tidymodels)

set.seed(123)
vb_split &lt;- initial_split(vb_df, strata = win)
vb_train &lt;- training(vb_split)
vb_test &lt;- testing(vb_split)</code></pre>
<pre class="r"><code>## decision tree不需要对数据中心化/step_dummy()
## 通过tune()设置待定超参数，在xgb_grid中设置调参的具体选项

xgb_spec &lt;- boost_tree(
  trees = 1000,
  tree_depth = tune(), min_n = tune(), loss_reduction = tune(),
  sample_size = tune(), mtry = tune(),
  learn_rate = tune()) %&gt;% ## 总共设置了6个超参数
  set_engine(&#39;xgboost&#39;) %&gt;% 
  set_mode(&#39;classificatoin&#39;)

xgb_spec
?grid_regular
?grid_latin_hypercube</code></pre>
<pre class="r"><code>?sample_size
?mtry
xgb_grid &lt;- grid_latin_hypercube(
  tree_depth(),
  min_n(),
  loss_reduction(),
  sample_size = sample_prop(),
  ## 调参可以通过训练集设定与数据集相近的参数，然后再根据得到的参数进行建模
  finalize(mtry(), vb_train),     ##如果直接用mtry()，会提示需要finalize() &#39;mtry&#39;
  learn_rate(),
  size = 20 ## 20个不同的模型
)

xgb_grid</code></pre>
<pre class="r"><code>xgb_wf &lt;- workflow() %&gt;% 
  add_formula(win ~ .) %&gt;% 
  add_model(xgb_spec)

xgb_wf</code></pre>
<pre class="r"><code>## 对训练接交叉验证
set.seed(123)
vb_folds &lt;- vfold_cv(vb_train, strata = win)
vb_folds</code></pre>
<pre class="r"><code>doParallel::registerDoParallel()

## set our tuning process（设置调参过程）
## 对10折数据框vb_folds，进行20个组合参数建模（xgb_grid,20行）
set.seed(234)
xgb_res &lt;- tune_grid(
  xgb_wf,                                  # what to tune
  resamples = vb_folds,                    # resample data
  grid = xgb_grid,                         # what possible parameter to try on our model
  control = control_grid(save_pred = TRUE) # see the predictions
)
## 然后选择最优的模型</code></pre>
</div>
<div id="explore-results" class="section level3">
<h3>Explore results</h3>
<pre class="r"><code>xgb_res %&gt;% 
  collect_metrics() %&gt;% # view() # 查看accuracy/roc_auc数值
  filter(.metric == &#39;roc_auc&#39;) %&gt;% 
  select(mean, mtry:sample_size) %&gt;% 
  pivot_longer(mtry:sample_size,
               names_to = &#39;parameter&#39;,
               values_to = &#39;value&#39;) %&gt;% 
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap( ~parameter, scales = &#39;free_x&#39;) ## 得到了我们的参数画图的效果</code></pre>
<pre class="r"><code># 展现较好的参数组合
show_best(xgb_res, &#39;roc_auc&#39;)

# 选择最优的参数
best_auc &lt;- select_best(xgb_res, &#39;roc_auc&#39;)

将最优的参数赋值给workflow为模型参数
final_xgb &lt;- finalize_workflow(xgb_wf, best_auc)
final_xgb</code></pre>
<pre class="r"><code>## variable importance，查看变量的重要性
library(vip)
final_xgb %&gt;% 
  fit(data = vb_train) %&gt;% 
  pull_workflow_fit() %&gt;% 
  vip(geom = &quot;point&quot;)
# kills/errors 是最重要的因素
# circuitAVP   不重要</code></pre>
<pre class="r"><code>?last_fit # Fit the final best model to training set and evaluate the test set
final_res &lt;- last_fit(final_xgb, vb_split)
# Training on the train set and Evaluating with test set

final_res %&gt;% 
  collect_metrics()
# 这个时候需要查看选择的参数是否过拟合overfitting</code></pre>
<pre class="r"><code>final_res %&gt;% 
  collect_predictions() %&gt;% # collect predictions in test set
  conf_mat() %&gt;%            # confusion matrix
  roc_curve(win, .pred_win) %&gt;% 
  autoplot()</code></pre>
</div>
</div>
<div id="sentiment-analysis-with-tidymodels-for-animal-crossing-user-review" class="section level2">
<h2>4. Sentiment analysis with tidymodels for Animal Crossing user review</h2>
<p>user reviews, how positive/negative the effect</p>
<p>Let’s build a model for <a href="https://github.com/tidy-tuesday/blob/master/data/2020/2020-05-05/readme.md">Anical Crossing user reviews from this week’s #tidymodel dataset</a>
Let’s predict the review rating from words in the review.</p>
<div id="explore-the-data-2" class="section level3">
<h3>Explore the data</h3>
<pre class="r"><code>library(tidyverse)

user_reviews &lt;- read_tsv(&quot;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/ser_reviews.tsv&quot;)</code></pre>
<pre class="r"><code>user_reviews %&gt;% 
  count(grade) %&gt;% 
  ggplot(aes(grade, n)) +
  geom_col()
# 不适合regressoin，采用classificatoin</code></pre>
<pre class="r"><code># 查看评论语句，需要提取/删除哪些内容？
user_reviews %&gt;% 
  filter(grade &gt; 8) %&gt;% 
  sample_n(5) %&gt;% 
  pull(text)

user_reviews %&gt;% 
  filter(grade &lt; 3) %&gt;% 
  sample_n(5) %&gt;% 
  pull(text)</code></pre>
<pre class="r"><code>reviews_parsed &lt;- user_reviews %&gt;% 
  mutate(text = str_remove(text, &quot;Expand$&quot;),
         rating = case_when(grade &gt; 6 ~ &quot;good&quot;),
                            TRUE      ~ &quot;bad&quot;)

reviews_parsed</code></pre>
<pre class="r"><code>library(tidytext)

words_per_review &lt;- reviews_parsed %&gt;% 
  unnest_tokens(word, text) %&gt;%
  count(user_name, name = &quot;total_words&quot;)

words_per_review %&gt;% 
  ggplot(aes(total_words)) +
  geom_histogram()</code></pre>
</div>
<div id="build-a-model-1" class="section level3">
<h3>Build a model</h3>
<pre class="r"><code>library(tidymodels)

set.seed(123)
review_split &lt;- initial_split(reviews_parsed, strata = rating)
review_train &lt;- training(reviews_parsed)
review_test &lt;- testing(reviews_parsed)</code></pre>
<pre class="r"><code>library(textrecipes)
# 如果感兴趣，还可以事实支持向量机和朴素贝叶斯分类器

review_rec &lt;- recipe(rating ~ text, data = review_train) %&gt;% 
  step_tokenize(text) %&gt;%     # take strings into words
  step_stopwords(text) %&gt;%    # 
  step_tokenfilter(text, max_tokens = 500) %&gt;% # 最多保留高词频的前500字
  step_tfidf(text) %&gt;%  ## 词频
  step_normalize(all_predictors())

review_prep &lt;- prep(review_rec)
review_prep
juice(review_prep)</code></pre>
<pre class="r"><code># Declare our model specification
lasso_spec &lt;- logistic_reg(penalty = tune(), mixture = 1) %&gt;% 
  set_engine(&quot;glmest&quot;)

lasso_wf &lt;- workflow() %&gt;% 
  add_recipe(review_rec) %&gt;% 
  add_model(lasso_spec)

lasso_wf</code></pre>
</div>
<div id="tune-model-parameters" class="section level3">
<h3>Tune model parameters</h3>
<pre class="r"><code>lambda_grid &lt;- grid_regular(penalty(), levels = 30) ## penalty()

set.seed(123)
review_folds &lt;- bootstraps(review_train, strata = rating)
review_folds</code></pre>
<pre class="r"><code>doParallel::registerDoParallel()

set.seed(2020)
lasso_grid &lt;- tune_grid(
  lasso_wf,
  resamples = review_folds,
  grid = lambda_grid,
  matrics = metric_set(roc_auc, npv)
)</code></pre>
<pre class="r"><code>lasso_grid %&gt;% 
  collect_metrics() %&gt;% 
  ggplot(aes(penalty, mean, color = .metric)) +
  geom_line(size = 0.5, show.legend = FALSE) +
  facet_wrap(~.metric) +
  scale_x_log10()  ## penalty is tranformed on log
## 从图中看出penalty在不同npv/ppv/roc_auc中的最优值</code></pre>
<pre class="r"><code>best_auc &lt;- lasso_grid %&gt;% 
  select_best(&quot;roc_auc&quot;)

best_auc

final_lasso &lt;- finalize_workflow(x = lasso_wf, parameters = best_auc)

final_lasso</code></pre>
<pre class="r"><code>library(vip)

final_lasso %&gt;%
  fit(review_train) %&gt;%
  pull_workflow_fit() %&gt;%  ## pull the fit model
  vi(lambda = best_auc$penalty) %&gt;% 
  group_by(Sign) %&gt;% 
  top_n(20, wt = abs(Importance)) %&gt;% 
  ungroup() %&gt;% 
  mutate(Importance = abs(Importance),
         Variable = str_remove(Variable, &quot;tfidf_text_&quot;),
         Variable = fct_reorder(Variable, Importance)) %&gt;% 
  ggplot(aes(x = Importance, y = Variable, fill = Sign)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~Sign, scales = &quot;free_y&quot;)</code></pre>
<pre class="r"><code># fit to the training data and evaluating the testing data
review_final &lt;- last_fit(final_lasso, review_split)

review_final %&gt;% 
  collect_metrics()

# Predictions, 逐步运行，查看测试集的混淆矩阵
review_final %&gt;%
  collect_predictions() %&gt;%
  conf_mat(rating, .pred_class) %&gt;% </code></pre>
</div>
<div id="choose-the-final-model" class="section level3">
<h3>Choose the final model</h3>
</div>
</div>
<div id="multinomial-classification-wi" class="section level2">
<h2>5. Multinomial classification wi</h2>
</div>
<div id="model-the-bechdel-test-for" class="section level2">
<h2>6. Model the bechdel test for</h2>
</div>
<div id="principal-component-analysis" class="section level2">
<h2>7. Principal component analysis</h2>
</div>
<div id="modeling-gdpr-violations" class="section level2">
<h2>8. Modeling GDPR violations</h2>
</div>
<div id="hyperparameter-tuning-using" class="section level2">
<h2>9. Hyperparameter tuning using</h2>
</div>
<div id="tuning-random-forest-hyperparameter" class="section level2">
<h2>10. Tuning random forest hyperparameter</h2>
</div>
<div id="robust-estimation-with-tidymodels" class="section level2">
<h2>11. Robust estimation with tidymodels</h2>
</div>
<div id="get-started-with-tidymodels" class="section level2">
<h2>12. Get started with tidymodels</h2>
</div>
<div id="lasso-regression-with" class="section level2">
<h2>13. Lasso regression with</h2>
</div>
<div id="predictive-modeling-in-r-with" class="section level2">
<h2>14. Predictive modeling in R with</h2>
</div>
<div id="data-preprocessing-and-re" class="section level2">
<h2>15. Data preprocessing and re</h2>
</div>
<div id="modeling-hotel-bookings-in" class="section level2">
<h2>16. Modeling hotel bookings in</h2>
</div>
<div id="topic-modeling-with-r-and-tidy-data-principal" class="section level2">
<h2>17. Topic modeling with R and tidy data principal</h2>
<p><em>参考文献</em>
- <a href="https://www.tidymodels.org/find/parsnip/">parsnip model选择</a></p>
<ul>
<li><a href="https://www.tidymodels.org/find/recipes/">receip step选择</a></li>
</ul>
</div>
